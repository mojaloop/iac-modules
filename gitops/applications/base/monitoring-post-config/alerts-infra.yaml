namespace: infra
groups:
  - name: storage
    interval: 1m
    rules:
      - alert: Node - Low Disk Space
        expr: ((node_filesystem_avail_bytes * 100) / node_filesystem_size_bytes < 20 and ON (instance, device, mountpoint) node_filesystem_readonly == 0) * on(instance) group_left (nodename) node_uname_info{nodename=~".+"}
        for: 2m
        labels:
          severity: warning
        annotations:
          summary: "{{ printf \"%.2f\" $value }}% disk space left. instance={{ $labels.nodename }}, mountpoint={{ $labels.mountpoint }}"
          description: "Disk is almost full (< 20% left)\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"
      - alert: Kubernetes - Low PVC Space
        expr: kubelet_volume_stats_used_bytes / kubelet_volume_stats_capacity_bytes *100 > 80
        for: 2m
        labels:
          severity: warning
        annotations:
          summary: "{{ printf \"%.2f\" $value }}% PVC space full.  persistentvolumeclaim={{ $labels.persistentvolumeclaim }}"
          description: "Volume is almost full (< 20% left)\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"
      - alert: ObjectStore - Bucket quota limit approaching
        expr: radosgw_usage_user_total_bytes / radosgw_usage_user_quota_size_bytes *100 > 80
        for: 2m
        labels:
          severity: warning
        annotations:
          summary: "Object store (s3 bucket) quota is {{ printf \"%.2f\" $value }}% used up for user={{ $labels.user }}"
          description: "LABELS = {{ $labels }}"
      - alert: RookCeph - OSD storage limit approaching
        expr: ceph_osd_stat_bytes_used/ceph_osd_stat_bytes *100 > 80
        for: 2m
        labels:
          severity: critical
        annotations:
          summary: "Ceph OSD={{ $labels.ceph_daemon }} is {{ printf \"%.2f\" $value }}% full. OSD={{ $labels.ceph_daemon }}"
          description: "LABELS = {{ $labels }}"
      - alert: RookCeph - Cluster storage limit approaching
        expr: ceph_cluster_total_used_bytes/ceph_cluster_total_bytes * 100 > 80
        for: 2m
        labels:
          severity: critical
        annotations:
          summary: "Ceph cluster={{ $labels.cluster }} is {{ printf \"%.2f\" $value }}% full. "
          description: "LABELS = {{ $labels }}"          
  - name: resources
    interval: 30s # TODO: update this after development
    rules:
      - alert: Node - High CPU usage
        expr: (1 - avg(rate(node_cpu_seconds_total{mode="idle"}[5m])) without (cpu)) * 100 > 80
        for: 2m
        labels:
          severity: warning
        annotations:
          summary: "Node={{ $labels.nodename }} is using {{ printf \"%.2f\" $value }}% CPU."
          description: "LABELS = {{ $labels }}"
      - alert: Node - High RAM usage
        expr: (1 - node_memory_MemAvailable_bytes/node_memory_MemTotal_bytes) * 100 > 80
        for: 2m
        labels:
          severity: warning
        annotations:
          summary: "Node={{ $labels.nodename }} is using {{ printf \"%.2f\" $value }}% RAM."
          description: "LABELS = {{ $labels }}"      
      - alert: K8s - Container CPU throttling
        expr: rate(container_cpu_cfs_throttled_seconds_total{image!="", container!=""}[5m]) > 0.3
        for: 2m
        labels:
          severity: warning
        annotations:
          summary: "Container={{ $labels.container }} in pod={{ $labels.pod }} is experiencing {{ printf \"%.2f\" $value }} seconds CPU throttling."
          description: "LABELS = {{ $labels }}" 
      - alert: K8s - High pod memory usage
        expr: sum(container_memory_working_set_bytes{image!=""}) by (cluster, job, namespace,pod,container) / sum(kube_pod_container_resource_limits{resource="memory"}) by (cluster, job, namespace,pod,container) * 100 > 80
        for: 2m
        labels:
          severity: warning
        annotations:
          summary: "Container={{ $labels.container }} in pod={{ $labels.namespace }}/{{ $labels.pod }} is using {{ printf \"%.2f\" $value }}% of memory limit."
          description: "LABELS = {{ $labels }}" 
      - alert: K8s - Container OOM restarts
        expr: (kube_pod_container_status_restarts_total - kube_pod_container_status_restarts_total offset 10m >= 1) and ignoring (reason) min_over_time(kube_pod_container_status_last_terminated_reason{reason="OOMKilled"}[10m]) == 1
        for: 0m
        labels:
          severity: warning
        annotations:
          summary: "Container={{ $labels.container }} in pod={{ $labels.namespace }}/{{ $labels.pod }} has been OOMKilled {{ $value }} times in the last 10 minutes."
          description: "Container {{ $labels.container }} in pod {{ $labels.namespace }}/{{ $labels.pod }} has been OOMKilled {{ $value }} times in the last 10 minutes.\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"




