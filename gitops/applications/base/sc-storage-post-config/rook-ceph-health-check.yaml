apiVersion: batch/v1
kind: Job
metadata:
  name: check-ceph-cluster-health
  namespace: ${ARGOCD_ENV_storage_namespace}
  annotations:
    argocd.argoproj.io/hook: PreSync
    argocd.argoproj.io/hook-delete-policy: HookSucceeded
    argocd.argoproj.io/sync-wave: '-11'  # Same wave as post-config
spec:
  template:
    spec:
      containers:
      - name: check-ceph-cluster-health
        image: bitnami/kubectl:latest
        command:
        - /bin/sh
        - -c
        - |
          # Wait for the Ceph cluster to be healthy
          until kubectl get cephcluster -n ${ARGOCD_ENV_storage_namespace} ${ARGOCD_ENV_storage_namespace} -o jsonpath='{.status.ceph.health}' | grep -q 'HEALTH_OK'; do
            echo "Waiting for Ceph cluster to be healthy..."
            sleep 30
          done
          # Wait for the cephblockpoolto be healthy
          until kubectl get cephblockpool -n ${ARGOCD_ENV_storage_namespace} ceph-blockpool -o jsonpath='{.status.phase}' | grep -q 'Ready'; do
            echo "CephBlockPool not yet ready, waiting..."
            sleep 30
          done
          # Wait for the cephobjectstore be healthy
          until kubectl get cephobjectstore -n ${ARGOCD_ENV_storage_namespace} default -o jsonpath='{.status.phase}' | grep -q 'Ready'; do
            echo "CephObjectStore not yet ready, waiting..."
            sleep 30
          done
      restartPolicy: OnFailure
      serviceAccountName: ceph-job-sa
  backoffLimit: 15
  ttlSecondsAfterFinished: 100